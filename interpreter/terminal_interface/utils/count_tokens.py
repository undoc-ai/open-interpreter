"""

Module for counting tokens and calculating costs based on token usage in different models.

This module provides functionality to count the number of tokens contained in texts and also calculates the cost
associated with the amount of tokens when interacting with language models such as GPT-4. It utilizes the `tiktoken`
library for token encoding and the `litellm` library to determine cost per token based on a given model.

Functions:
    count_tokens(text, model): Counts the number of tokens in the provided text as per the specified language model's encoder.
    token_cost(tokens, model): Computes the cost of the provided number of tokens for the given model.
    count_messages_tokens(messages, model): Counts the total number of tokens in a collection of messages, which can be a mix of strings and dictionaries containing various textual elements, for the specified model and computes the total cost.

Note: Documentation automatically generated by https://undoc.ai
"""
import tiktoken
from litellm import cost_per_token


def count_tokens(text="", model="gpt-4"):
    """
        Counts the number of tokens in a given text using a specified language model encoder.
        This function takes a piece of text and the model name of the encoder to be used for tokenization.
        It returns the count of tokens obtained from encoding the supplied text. This is particularly
        useful when working with models like GPT-4, which have a maximum token limit for inputs.
        Parameters:
            text (str, optional): The text to be tokenized and counted. Defaults to an empty string.
            model (str): The name of the model based on which the text will be tokenized. It expects
                a string that represents any of the supported model names like 'gpt-4'.
        Returns:
            int: The number of tokens resulted from encoding the text.
        Raises:
            ValueError: If the provided model name does not correspond to any known encoders.
    """

    encoder = tiktoken.encoding_for_model(model)

    return len(encoder.encode(text))


def token_cost(tokens=0, model="gpt-4"):
    """
        Calculate the cost for a given number of tokens using a specified language model.
        This function computes the monetary cost of using a certain number of tokens with a specified language model. The cost is rounded to six decimal places.
        Args:
            tokens (int, optional): The number of tokens to calculate the cost for. Defaults to 0.
            model (str, optional): The identifier for the language model to be used for cost calculation. Defaults to 'gpt-4'.
        Returns:
            float: The calculated cost rounded to six decimal places.
    """

    (prompt_cost, _) = cost_per_token(model=model, prompt_tokens=tokens)

    return round(prompt_cost, 6)


def count_messages_tokens(messages=[], model=None):
    """
    Calculate the total number of tokens and their cost from a list of messages.
    This function counts the number of tokens for each message in the provided list of messages. Each message can be a string or
    a dictionary containing 'message', 'code', and/or 'output' fields, with respective contents to be tokenized. The token
    count is aggregated, and the total cost is calculated based on the specified model, using a separate function to
    determine the cost for the accumulated tokens.
    Args:
        messages (list, optional): A list of messages where each message can be either a string or a dictionary with possible
                                     keys including 'message', 'code', and 'output'. Defaults to an empty list.
        model (str, optional): The name of the language model for which the tokens are being counted, used to determine
                               the cost per token. Defaults to None.
    Returns:
        tuple: A tuple with two elements:
                 - The first element is an integer representing the total token count for all messages.
                 - The second element is a float representing the total cost for all tokens, according to the model specified.
    """

    tokens_used = 0

    for message in messages:
        if isinstance(message, str):
            tokens_used += count_tokens(message, model=model)
        elif "message" in message:
            tokens_used += count_tokens(message["message"], model=model)

            if "code" in message:
                tokens_used += count_tokens(message["code"], model=model)

            if "output" in message:
                tokens_used += count_tokens(message["output"], model=model)

    prompt_cost = token_cost(tokens_used, model=model)

    return (tokens_used, prompt_cost)
