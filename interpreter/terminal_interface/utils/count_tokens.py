"""



Module for counting tokens and calculating costs based on token usage in different models.

This module provides functionality to count the number of tokens contained in texts and also calculates the cost
associated with the amount of tokens when interacting with language models such as GPT-4. It utilizes the `tiktoken`
library for token encoding and the `litellm` library to determine cost per token based on a given model.

Functions:
    count_tokens(text, model): Counts the number of tokens in the provided text as per the specified language model's encoder.
    token_cost(tokens, model): Computes the cost of the provided number of tokens for the given model.
    count_messages_tokens(messages, model): Counts the total number of tokens in a collection of messages, which can be a mix of strings and dictionaries containing various textual elements, for the specified model and computes the total cost.

Note: Documentation automatically generated by https://undoc.ai
"""
import tiktoken
from litellm import cost_per_token


def count_tokens(text="", model="gpt-4"):

    encoder = tiktoken.encoding_for_model(model)

    return len(encoder.encode(text))


def token_cost(tokens=0, model="gpt-4"):
    """
        Calculate the cost for a given number of tokens using a specified language model.
        This function computes the monetary cost of using a certain number of tokens with a specified language model. The cost is rounded to six decimal places.
        Args:
            tokens (int, optional): The number of tokens to calculate the cost for. Defaults to 0.
            model (str, optional): The identifier for the language model to be used for cost calculation. Defaults to 'gpt-4'.
        Returns:
            float: The calculated cost rounded to six decimal places.
    """

    (prompt_cost, _) = cost_per_token(model=model, prompt_tokens=tokens)

    return round(prompt_cost, 6)


def count_messages_tokens(messages=[], model=None):

    tokens_used = 0

    for message in messages:
        if isinstance(message, str):
            tokens_used += count_tokens(message, model=model)
        elif "message" in message:
            tokens_used += count_tokens(message["message"], model=model)

            if "code" in message:
                tokens_used += count_tokens(message["code"], model=model)

            if "output" in message:
                tokens_used += count_tokens(message["output"], model=model)

    prompt_cost = token_cost(tokens_used, model=model)

    return (tokens_used, prompt_cost)
