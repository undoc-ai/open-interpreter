"""

Module that transforms text-based AI outputs to enable the execution of code on a user's machine.

This module contains a function which wraps around a language model designed for text interaction and
adds the capability to execute code. The core functionality is to detect code blocks within messages
and handle them appropriately, either by executing the code or by appending the code syntax to the
language model's outputs.

The `convert_to_coding_llm` function asserts that a system message is the first in the series and
amends the system instructions to clarify the process for code execution. It adjusts the final message
in preparation for output generation and ensures that the `convert_to_openai_messages` function is
applied without function calls.

The module adjusts messages for clarity when the user attempts to use Jupyter notebook commands,
and processes text blocks that do not contain code in the usual manner while handling code blocks
separately.

Note: Documentation automatically generated by https://undoc.ai
"""
from ..utils.convert_to_openai_messages import convert_to_openai_messages
from .setup_text_llm import setup_text_llm


def convert_to_coding_llm(text_llm, debug_mode=False):
    """
    Converts a text language model (LLM) to a coding LLM, enhancing its capabilities to execute code.
    The function wraps a given LLM with additional instructions and post-processing to handle code execution. It asserts the presence of a system message initiating the conversation about executing code and conditions message processing based on whether the text contains code block markers. The function is designed to interpret and yield code blocks in the appropriate programming language, while regular text is yielded as messages. A debug mode can be toggled to print processing details.
    Args:
       text_llm (callable): A callable that takes messages as input and yields responses.
       debug_mode (bool): If True, prints each chunk of data during the processing for debugging purposes. Defaults to False.
    Returns:
       callable: A wrapped version of the text LLM that can process and execute code blocks in messages.
    Raises:
       AssertionError: If the first message does not have 'system' as the role.
    """

    def coding_llm(messages):
        """
        Handles the processing of messages in a conversational interface that permits code execution on the user's machine. The function manages text messages and code blocks within the communication, ensuring that the proper formatting and language specifications for executable code are maintained. If the message indicates code execution, it converts the content into a format that is amenable for execution by appending appropriate fields to the output. All non-code messages are passed as is. The function supports diverse programming languages and does not require a Jupyter notebook context, signaling to users when a shell-like syntax is misapplied. The process involves multiple stages including text massaging, code block detection, and execution flagging, while also providing debugging outputs when enabled.
        Args:
            messages (list of dict): A list of message dictionaries, structured with keys such as 'role', 'message', and 'code'. The first message is expected to have a 'system' role providing context for the interaction.
        Returns:
            generator: A generator that yields dictionaries with keys 'message', 'code', or 'language' reflecting the processed content of each conversational turn. Messages may contain instructions or communication intended for the user, while code sections are annotated with the language and the actual code which needs to be executed. The generator pauses after yielding each piece of content, allowing for the execution flow to be managed externally.
        """
        # First, tell it how to run code.

        # System message method:
        assert messages[0]["role"] == "system"
        messages[0][
            "message"
        ] += "\nTo execute code on the user's machine, write a markdown code block. Specify the language after the ```. You will receive the output. Use any programming language."

        # Gaslight method (DISABLED):
        '''
        gaslight = None
        if messages[-1]["role"] == "user":
            # Last message came from the user.
            if messages[-1]["message"].lower() not in [
                "hello",
                "hi",
                "hey",
                "helo",
                "hii",
                "hi!",
            ]:  # :)
                gaslight = """Let's explore this. I can run code on your machine by writing the code in a markdown code block. This works if I put a newline after ```shell, ```python, ```applescript, etc. then write code. I'm going to try to do this for your task **after I make a plan**. I'll put the *correct* language after the "```"."""
        else:
            # Last message came from the assistant.

            # (The below should actually always be True in OI if last message came from the assistant)
            # I think we don't need this actually.
            """
            if "output" in messages[-1]:
                if messages[-1]["output"] != "No output":
                    gaslight = "(Thought: I see that the code I just ran produced an output. The next message I send will go to the user.)"
                elif messages[-1]["output"] == "No output":
                    gaslight = "(Thought: I see that the code I just ran produced no output. The next message I send will go to the user.)"
            """

        if gaslight:
            messages.append({"role": "assistant", "message": gaslight})
        '''

        # If it tried to use Jupyter, let it know.
        if "code" in messages[-1]:
            if any([line.startswith("!") for line in messages[-1]["code"].split("\n")]):
                if "syntax" in messages[-1]["output"].lower():  # Detect error
                    messages[-1][
                        "output"
                    ] += "\nRemember you are not in a Jupyter notebook. Run shell by writing a markdown shell codeblock, not '!'."

        messages = convert_to_openai_messages(messages, function_calling=False)

        inside_code_block = False
        accumulated_block = ""
        language = None

        for chunk in text_llm(messages):
            if debug_mode:
                print("Chunk in coding_llm", chunk)

            if "choices" not in chunk or len(chunk["choices"]) == 0:
                # This happens sometimes
                continue

            content = chunk["choices"][0]["delta"].get("content", "")

            accumulated_block += content

            if accumulated_block.endswith("`"):
                # We might be writing "```" one token at a time.
                continue

            # Did we just enter a code block?
            if "```" in accumulated_block and not inside_code_block:
                inside_code_block = True
                accumulated_block = accumulated_block.split("```")[1]

            # Did we just exit a code block?
            if inside_code_block and "```" in accumulated_block:
                return

            # If we're in a code block,
            if inside_code_block:
                # If we don't have a `language`, find it
                if language is None and "\n" in accumulated_block:
                    language = accumulated_block.split("\n")[0]

                    # Default to python if not specified
                    if language == "":
                        language = "python"
                    else:
                        # Removes hallucinations containing spaces or non letters.
                        language = "".join(char for char in language if char.isalpha())

                    output = {"language": language}

                    # If we recieved more than just the language in this chunk, send that
                    if content.split("\n")[1]:
                        output["code"] = content.split("\n")[1]

                    yield output

                # If we do have a `language`, send the output as code
                elif language:
                    yield {"code": content}

            # If we're not in a code block, send the output as a message
            if not inside_code_block:
                yield {"message": content}

    return coding_llm
